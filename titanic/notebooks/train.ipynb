{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\dataset\\input\\gender_submission.csv\n",
      ".\\dataset\\input\\test.csv\n",
      ".\\dataset\\input\\train.csv\n",
      ".\\dataset\\output\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for directory,_,files in os.walk('.\\dataset'):\n",
    "    for file in files:\n",
    "        print(os.path.join(directory,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_path = \"./dataset/input/train.csv\"\n",
    "test_path  = \"./dataset/input/test.csv\"\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Percentage of NA per property sorted\n",
      "--------\n",
      "Cabin          77.104377\n",
      "Age            19.865320\n",
      "Embarked        0.224467\n",
      "PassengerId     0.000000\n",
      "Survived        0.000000\n",
      "Pclass          0.000000\n",
      "Name            0.000000\n",
      "Sex             0.000000\n",
      "SibSp           0.000000\n",
      "Parch           0.000000\n",
      "Ticket          0.000000\n",
      "Fare            0.000000\n",
      "dtype: float64\n",
      "--------\n",
      "Unique values for duplications and other useful info\n",
      "--------\n",
      "Survived         2\n",
      "Sex              2\n",
      "Pclass           3\n",
      "Embarked         3\n",
      "SibSp            7\n",
      "Parch            7\n",
      "Age             88\n",
      "Cabin          147\n",
      "Fare           248\n",
      "Ticket         681\n",
      "PassengerId    891\n",
      "Name           891\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('--------')\n",
    "print('Percentage of NA per property sorted')\n",
    "print('--------')\n",
    "p = (train.isna().sum()/len(train)*100).sort_values(ascending=False)\n",
    "print(p)\n",
    "print('--------')\n",
    "print('Unique values for duplications and other useful info')\n",
    "print('--------')\n",
    "u = train.nunique().sort_values()\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347082      7\n",
       "CA. 2343    7\n",
       "1601        7\n",
       "3101295     6\n",
       "CA 2144     6\n",
       "           ..\n",
       "9234        1\n",
       "19988       1\n",
       "2693        1\n",
       "PC 17612    1\n",
       "370376      1\n",
       "Name: Ticket, Length: 681, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def cleanData(data):    \n",
    "    # Data missing and categorical to drop\n",
    "    data.drop(['Cabin','Name','Ticket'], axis=1, inplace=True)\n",
    "\n",
    "    # Data missing Case2\n",
    "    data['Age'] = data.groupby(['Pclass','Sex'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    # FARE Data missing in test\n",
    "    data['Fare'] = data.groupby(['Pclass','Sex'])['Fare'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    # Data missing Case3\n",
    "    data.dropna(axis=0, subset=['Embarked'], inplace=True)\n",
    "    \n",
    "    # Categorical Data\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    \n",
    "    # Sex\n",
    "    data['Sex'].replace({'male':0, 'female':1}, inplace=True)\n",
    "    \n",
    "    # Embarked\n",
    "    data['Embarked'].replace({'S':0, 'C':1, 'Q':2}, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train = cleanData(train)\n",
    "clean_test = cleanData(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 889 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  889 non-null    int64  \n",
      " 1   Survived     889 non-null    int64  \n",
      " 2   Pclass       889 non-null    int64  \n",
      " 3   Sex          889 non-null    int64  \n",
      " 4   Age          889 non-null    float64\n",
      " 5   SibSp        889 non-null    int64  \n",
      " 6   Parch        889 non-null    int64  \n",
      " 7   Fare         889 non-null    float64\n",
      " 8   Embarked     889 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 69.5 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 0 to 417\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Sex          418 non-null    int64  \n",
      " 3   Age          418 non-null    float64\n",
      " 4   SibSp        418 non-null    int64  \n",
      " 5   Parch        418 non-null    int64  \n",
      " 6   Fare         418 non-null    float64\n",
      " 7   Embarked     418 non-null    int64  \n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 29.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(clean_train.info())\n",
    "print(clean_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "# Set X and y\n",
    "y = train['Survived']\n",
    "X = pd.get_dummies(train.drop('Survived', axis=1))\n",
    "\n",
    "# Split model train test data\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  1 : LogisticRegression(random_state=42, solver='liblinear')\n",
      "ACC:  0.797752808988764\n",
      "Model  2 : GradientBoostingClassifier()\n",
      "ACC:  0.8202247191011236\n",
      "Model  3 : RandomForestClassifier()\n",
      "ACC:  0.797752808988764\n",
      "Model  4 : SGDClassifier()\n",
      "ACC:  0.7303370786516854\n",
      "Model  5 : SVC()\n",
      "ACC:  0.6348314606741573\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "def fitAndPredict(model):\n",
    "    \"\"\"The following code makes faster to evaluate a model \n",
    "    automating the fit and accuracy process\"\"\"\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_val)\n",
    "    return metrics.accuracy_score(y_val, prediction)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Lets some models\n",
    "model1 = LogisticRegression(solver='liblinear', random_state=42)\n",
    "model2 = GradientBoostingClassifier()\n",
    "model3 = RandomForestClassifier()\n",
    "model4 = SGDClassifier()\n",
    "model5 = SVC()\n",
    "\n",
    "models = [model1, model2, model3, model4, model5]\n",
    "i = 0\n",
    "for model in models:\n",
    "    i +=1\n",
    "    print(\"Model \", i,\":\", model)\n",
    "    print(\"ACC: \", fitAndPredict(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370786516853933"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(min_samples_split=20, min_samples_leaf=60, max_depth=3, max_features=7)\n",
    "fitAndPredict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(pd.get_dummies(clean_test))\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': clean_test.PassengerId, 'Survived': predict})\n",
    "output.to_csv('./output/submission.csv', index=False)\n",
    "print(\"Submission saved\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fbcc1eec51d10e8d5cdcc21f160636fa163959b1399dd3e654e479c291d5e1c6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('kaggle': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
